{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sqlalchemy import create_engine, text as sql_text\n",
    "import json\n",
    "from datetime import datetime\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Database configuration\n",
    "db_eng = create_engine('postgresql+psycopg2://postgres:postgres@localhost:5432/airbnb',\n",
    "                       connect_args={'options': '-csearch_path=new_york_city'},\n",
    "                       echo=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with db_eng.connect() as conn:\n",
    "    # Add a column if it does not exist\n",
    "    conn.execute(sql_text(\"\"\"\n",
    "    ALTER TABLE reviews ADD COLUMN IF NOT EXISTS comments_tsv tsvector;\n",
    "    \"\"\"))\n",
    "    # Update the new column with data\n",
    "    conn.execute(sql_text(\"\"\"\n",
    "    UPDATE reviews SET comments_tsv = to_tsvector(comments);\n",
    "    \"\"\"))\n",
    "    # Create a GIN index if it does not exist\n",
    "    conn.execute(sql_text(\"\"\"\n",
    "    CREATE INDEX IF NOT EXISTS comments_tsv_in_reviews ON reviews USING GIN (comments_tsv);\n",
    "    \"\"\"))\n",
    "    conn.commit()  # Ensure all changes are committed to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_drop_index(conn, action, index_name, column, table):\n",
    "    \"\"\"Add or drop an index based on the action.\"\"\"\n",
    "    if action == 'add':\n",
    "        query = f\"\"\"\n",
    "        BEGIN;\n",
    "        CREATE INDEX IF NOT EXISTS {index_name} ON {table} ({column});\n",
    "        COMMIT;\n",
    "        \"\"\"\n",
    "    elif action == 'drop':\n",
    "        query = f\"\"\"\n",
    "        BEGIN;\n",
    "        DROP INDEX IF EXISTS {index_name};\n",
    "        COMMIT;\n",
    "        \"\"\"\n",
    "\n",
    "# Function to run a query multiple times and collect performance data\n",
    "def run_query_and_collect_data(query, conn, count=1):\n",
    "    times = []\n",
    "    for _ in range(count):\n",
    "        start = datetime.now()\n",
    "        conn.execute(sql_text(query))\n",
    "        end = datetime.now()\n",
    "        times.append((end - start).total_seconds())\n",
    "    return {\n",
    "        'avg': np.round(np.mean(times), 4),\n",
    "        'min': np.round(np.min(times), 4),\n",
    "        'max': np.round(np.max(times), 4),\n",
    "        'std': np.round(np.std(times), 4),\n",
    "        'count': count,\n",
    "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "\n",
    "words = ['horrible', 'awesome', 'apartment']\n",
    "years = [2009, 2010, 2011, 2012, 2013, 2014, 2017, 2019, 2023]\n",
    "results = {}\n",
    "\n",
    "with db_eng.connect() as conn:\n",
    "    for year in years:\n",
    "        for word in words:\n",
    "            query_key = f\"{word}_{year}\"\n",
    "            results[query_key] = {}\n",
    "            \n",
    "            # Define the index name\n",
    "            index_name = f\"datetime_idx_on_{year}\"\n",
    "            \n",
    "            ts_query = f\"SELECT count(*) FROM reviews WHERE comments_tsv @@ to_tsquery('{word}') AND datetime BETWEEN '{year}-01-01' AND '{year}-12-31';\"\n",
    "            ilike_query = f\"SELECT count(*) FROM reviews WHERE comments ILIKE '%%{word}%%' AND datetime BETWEEN '{year}-01-01' AND '{year}-12-31';\"\n",
    "            \n",
    "            # Drop datetime index for the LIKE query\n",
    "            add_drop_index(conn, 'drop', index_name, 'datetime', 'reviews')\n",
    "            results[query_key]['__'] = run_query_and_collect_data(ilike_query, conn)\n",
    "            results[query_key]['__comments_tsv_in_reviews__'] = run_query_and_collect_data(ts_query, conn)\n",
    "\n",
    "            # Re-create datetime index for the indexed queries\n",
    "            add_drop_index(conn, 'add', index_name, 'datetime', 'reviews')\n",
    "            results[query_key]['__datetime_in_reviews__'] = run_query_and_collect_data(ilike_query, conn)\n",
    "            results[query_key]['__datetime_in_reviews__comments_tsv_in_reviews__'] = run_query_and_collect_data(ts_query, conn)\n",
    "            print(f\"{query_key}: {json.dumps(results[query_key], indent=4)}\")\n",
    "\n",
    "\n",
    "# Sorting the dictionary by keys in the order of words and then years\n",
    "sorted_keys = sorted(results.keys(), key=lambda x: (x.split('_')[0], int(x.split('_')[1])))\n",
    "sorted_results = OrderedDict((k, results[k]) for k in sorted_keys)\n",
    "\n",
    "# Write performance data to JSON in sorted order\n",
    "with open('perf_data/text_search_query.json', 'w') as file:\n",
    "    json.dump(sorted_results, file, indent=4)\n",
    "\n",
    "print(\"Performance data has been recorded successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
