{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'datetime' column successfully added.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, text as sql_text\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "DATABASE_URL = 'postgresql+psycopg2://postgres:password@localhost:5432/airbnb'\n",
    "SCHEMA = 'new_york_city'\n",
    "PERF_DATA_DIR = 'perf_data'\n",
    "\n",
    "# Connect to the database\n",
    "engine = create_engine(DATABASE_URL, connect_args={'options': f'-csearch_path={SCHEMA}'}, echo=True)\n",
    "\n",
    "# Update and add datetime column to reviews\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(sql_text(\"\"\"\n",
    "        ALTER TABLE reviews ADD COLUMN IF NOT EXISTS datetime TIMESTAMP;\n",
    "        UPDATE reviews SET datetime = TO_TIMESTAMP(TO_CHAR(date, 'YYYY-MM-DD') || ' 12:00:00', 'YYYY-MM-DD HH24:MI:SS');\n",
    "    \"\"\"))\n",
    "    conn.commit()\n",
    "\n",
    "# Function to run query and collect performance data\n",
    "def run_query_and_collect_data(query, engine):\n",
    "    times = []\n",
    "    with engine.connect() as conn:\n",
    "        for _ in range(50):  # Run the query multiple times to average out the performance\n",
    "            start_time = datetime.now()\n",
    "            conn.execute(sql_text(query))\n",
    "            end_time = datetime.now()\n",
    "            times.append((end_time - start_time).total_seconds())\n",
    "    return {\n",
    "        \"avg\": np.mean(times),\n",
    "        \"min\": np.min(times),\n",
    "        \"max\": np.max(times),\n",
    "        \"std\": np.std(times),\n",
    "        \"exec_count\": len(times),\n",
    "        \"timestamp\": datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add or drop index and fetch current indexes on the table\n",
    "def add_drop_index(engine, action, column, table):\n",
    "    index_name = f\"idx_{column}_in_{table}\"\n",
    "    if action == 'add':\n",
    "        query = sql_text(f\"CREATE INDEX {index_name} ON {table}({column});\")\n",
    "    elif action == 'drop':\n",
    "        query = sql_text(f\"DROP INDEX IF EXISTS {index_name};\")\n",
    "    with engine.connect() as conn:\n",
    "        conn.execute(query)\n",
    "\n",
    "# Function to calculate time difference\n",
    "def time_diff(start_time, end_time):\n",
    "    return (end_time - start_time).total_seconds()\n",
    "\n",
    "# Function to execute a query and measure time\n",
    "def run_query(query, conn):\n",
    "    times = []\n",
    "    for _ in range(1):\n",
    "        start_time = datetime.now()\n",
    "        conn.execute(sql_text(query))\n",
    "        end_time = datetime.now()\n",
    "        times.append(time_diff(start_time, end_time))\n",
    "    return times\n",
    "\n",
    "# Function to compute performance metrics\n",
    "def compute_metrics(times):\n",
    "    return {\n",
    "        \"avg\": round(np.mean(times), 4),\n",
    "        \"min\": round(np.min(times), 4),\n",
    "        \"max\": round(np.max(times), 4),\n",
    "        \"std\": round(np.std(times), 4),\n",
    "        \"exec_count\": len(times),\n",
    "        \"timestamp\": datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "\n",
    "# Function to build the index description key\n",
    "def build_index_description_key(all_indexes, spec):\n",
    "    description_key = \"\"\n",
    "    for index in all_indexes:\n",
    "        if index in spec:\n",
    "            description_key += f\"__{index[0]}_in_{index[1]}\"\n",
    "    description_key += \"__\"\n",
    "    return description_key\n",
    "\n",
    "# Fetch performance data\n",
    "def fetch_perf_data(filename):\n",
    "    try:\n",
    "        with open(filename) as f:\n",
    "            if os.stat(filename).st_size == 0:\n",
    "                return {}\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return {}\n",
    "\n",
    "# Write performance data\n",
    "def write_perf_data(data, filename):\n",
    "    with open(filename, 'w') as fp:\n",
    "        json.dump(data, fp, indent=4)\n",
    "\n",
    "# Create queries for each year from 2009 to 2024\n",
    "q_dict = {}\n",
    "for yr in range(2009, 2025):\n",
    "    q_name = 'listings_join_review_' + str(yr)\n",
    "    date_start = str(yr) + '-01-01 00:00:00'\n",
    "    date_end = str(yr) + '-12-31 23:59:59'\n",
    "    q_dict[q_name] = build_query_listings_reviews(date_start, date_end)\n",
    "\n",
    "pprint.pp(q_dict)\n",
    "\n",
    "perf_summary_path = 'perf_data/listings_join_reviews.json'\n",
    "if not os.path.exists(perf_summary_path):\n",
    "    with open(perf_summary_path, 'w') as f:\n",
    "        json.dump({}, f)\n",
    "\n",
    "perf_summary = fetch_perf_data(perf_summary_path)\n",
    "\n",
    "all_indexes = [['datetime','reviews'], ['id','listings']]\n",
    "specs = [\n",
    "    [['datetime','reviews'], ['id','listings']],\n",
    "    [['datetime','reviews']],\n",
    "    [['id','listings']],\n",
    "    []\n",
    "]\n",
    "\n",
    "for query_name, query in q_dict.items():\n",
    "    for spec in specs:\n",
    "        print('Processing spec: ', str(spec), '\\n')\n",
    "\n",
    "        for index in all_indexes:\n",
    "            if index not in spec:\n",
    "                add_drop_index(db_eng, 'drop', index[0], index[1])\n",
    "                print('\\nAfter dropping', str(index))\n",
    "\n",
    "        for index in spec:\n",
    "            add_drop_index(db_eng, 'add', index[0], index[1])\n",
    "            print('\\nAfter adding', str(index))\n",
    "\n",
    "        time_list = []\n",
    "        for i in range(50):\n",
    "            with db_eng.connect() as conn:\n",
    "                times = run_query(query, conn)\n",
    "            time_list.extend(times)\n",
    "        \n",
    "        perf_profile = compute_metrics(time_list)\n",
    "\n",
    "        print('\\nThe list of running times is as follows:')\n",
    "        pprint.pp(time_list)\n",
    "\n",
    "        print('\\nThe statistics on the list of running times are as follows:')\n",
    "        pprint.pp(perf_profile)\n",
    "\n",
    "        key_value = build_index_description_key(all_indexes, spec)\n",
    "        print('\\nThe new value for \"' + key_value + '\" will be', str(perf_profile))\n",
    "\n",
    "        if query_name in perf_summary:\n",
    "            perf_dict = perf_summary[query_name]\n",
    "            print(\"\\nBefore modifying perf_dict, the value of perf_summary[query_name] (if it existed) was: \")\n",
    "            pprint.pp(perf_dict)\n",
    "        else:\n",
    "            perf_dict = {}\n",
    "            print(\"\\nBefore modifying perf_dict, the value of perf_summary[query_name] had empty value\")\n",
    "        print()\n",
    "        perf_dict[key_value] = perf_profile\n",
    "        perf_summary[query_name] = perf_dict\n",
    "\n",
    "        print(\"\\nAfter modifying perf_dict, the value of perf_summary[query_name] is: \")\n",
    "        pprint.pp(perf_summary[query_name])\n",
    "        print()\n",
    "\n",
    "        print('\\nThe full value of perf_summary is:')\n",
    "        pprint.pp(perf_summary)\n",
    "\n",
    "        write_perf_data(perf_summary, perf_summary_path)\n",
    "\n",
    "print(\"JSON files created successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
